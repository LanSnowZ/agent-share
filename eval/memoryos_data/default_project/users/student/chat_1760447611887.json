{
  "id": "chat_1760447611887",
  "username": "student",
  "model": "gpt-4o-mini",
  "shared_memory_enabled": true,
  "personal_memory_enabled": true,
  "created_at": "2025-10-14 21:14:17",
  "updated_at": "2025-10-14 21:15:06",
  "messages": [
    {
      "type": "user",
      "content": "ragæ€ä¹ˆå­¦ä¹ ",
      "timestamp": "2025-10-14 21:14:17"
    },
    {
      "type": "assistant",
      "content": "å¤ªæ£’äº†ï¼ŒStudentï¼ğŸ¯ ä½ åˆåœ¨æ·±å…¥ç ”ç©¶ RAG äº†ï¼è®©æˆ‘ç»™ä½ ä¸€ä¸ªæ¸…æ™°ã€å¾ªåºæ¸è¿›çš„å­¦ä¹ è·¯å¾„ï¼Œå¸®åŠ©ä½ ç†è§£ RAG çš„å­¦ä¹ æœºåˆ¶ï¼Œå¹¶èƒ½è‡ªå·±å®ç°ä¸€ä¸ªå° Demoã€‚\n\n## ğŸ§­ ä¸€ã€äº†è§£ RAG çš„åŸºæœ¬æ¦‚å¿µ\n\n**RAGï¼ˆRetrieval-Augmented Generationï¼‰= æ£€ç´¢ + ç”Ÿæˆ**\n\nç®€å•æ¥è¯´ï¼ŒRAG çš„å·¥ä½œæ–¹å¼æ˜¯ï¼š\n1. å½“ä½ æé—®æ—¶ï¼Œç³»ç»Ÿé¦–å…ˆä¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„ä¿¡æ¯ã€‚\n2. ç„¶åæŠŠè¿™äº›æ£€ç´¢åˆ°çš„å†…å®¹å’Œä½ çš„é—®é¢˜ä¸€èµ·è¾“å…¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚\n3. æ¨¡å‹åŸºäºè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå›ç­”ï¼Œè¿™æ ·çš„å›ç­”é€šå¸¸æ›´åŠ å‡†ç¡®å’Œå¯é ã€‚\n\n> æƒ³è±¡ä¸€ä¸‹ RAG å°±æ˜¯ä¸€ä¸ªâ€œå¸¦æœç´¢åŠŸèƒ½çš„ ChatGPTâ€ï¼\n\n---\n\n## ğŸ§± äºŒã€å…¥é—¨å‡†å¤‡ï¼ˆ1~2 å‘¨ï¼‰\n\nåœ¨ä½ å¼€å§‹ä¹‹å‰ï¼Œæœ‰å‡ ä¸ªå…³é”®çš„çŸ¥è¯†ç‚¹éœ€è¦æŒæ¡ï¼Œç¡®ä¿ä½ èƒ½é¡ºåˆ©è·‘é€šå°ä¾‹å­ï¼š\n\n| æ¨¡å— | é‡ç‚¹ç†è§£ | ç»ƒä¹ å»ºè®® |\n|------|------------|-----------|\n| **Python åŸºç¡€** | ç†è§£å¯¼åŒ…ã€å‡½æ•°å’Œç±» | å¯ä»¥å‚è€ƒã€ŠPython ç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µã€‹ |\n| **Embeddingï¼ˆæ–‡æœ¬å‘é‡ï¼‰** | äº†è§£å¦‚ä½•å°†æ–‡å­—è½¬æˆæ•°å­—åŒ–è¡¨ç¤º | è·‘ä¸‹é¢çš„ç›¸ä¼¼åº¦æµ‹è¯•ä»£ç  |\n| **å‘é‡æ•°æ®åº“** | å­¦ä¹ å¦‚ä½•å­˜å‚¨å’Œæ£€ç´¢ç›¸ä¼¼æ–‡æœ¬ | åˆæ­¥æ¥è§¦ FAISS æˆ– Chroma |\n\n### ç›¸ä¼¼åº¦æµ‹è¯•ç¤ºä¾‹ä»£ç ï¼š\n```python\nfrom sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nemb1 = model.encode(\"çŒ«å–œæ¬¢æ™’å¤ªé˜³\", convert_to_tensor=True)\nemb2 = model.encode(\"çŒ«åœ¨é˜³å…‰ä¸‹ä¼‘æ¯\", convert_to_tensor=True)\n\nprint(util.cos_sim(emb1, emb2))  # ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œæ–‡æœ¬è¶Šâ€œåƒâ€\n```\n\n---\n\n## âš™ï¸ ä¸‰ã€RAG çš„ä¸‰å¤§æ ¸å¿ƒç»„ä»¶\n\nç†è§£è¿™ä¸‰å¤§ç»„ä»¶æ˜¯æ„å»º RAG ç³»ç»Ÿçš„åŸºç¡€ï¼š\n\n| æ¨¡å— | èŒè´£ | å·¥å…·ç¤ºä¾‹ |\n|------|------|----------|\n| **Retrieverï¼ˆæ£€ç´¢å™¨ï¼‰** | ä»çŸ¥è¯†åº“ä¸­æ‰¾å‡ºæœ€ç›¸å…³çš„å†…å®¹ | Chroma / FAISS |\n| **Augmenterï¼ˆå¢å¼ºå™¨ï¼‰** | ç»„åˆé—®é¢˜å’Œæ£€ç´¢ç»“æœï¼Œå½¢æˆ prompt | LangChain / LlamaIndex |\n| **Generatorï¼ˆç”Ÿæˆå™¨ï¼‰** | è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆå›ç­” | OpenAI / Claude / Ollama / Llama3 |\n\næŒæ¡è¿™ä¸‰éƒ¨åˆ†ï¼Œä½ å°±èƒ½æ­å»ºä¸€ä¸ªå®Œæ•´çš„ RAG æµç¨‹ã€‚\n\n---\n\n## ğŸ’» å››ã€ä½ çš„ç¬¬ä¸€ä¸ª RAG Demoï¼šPDF é—®ç­”æœºå™¨äºº\n\n### Step 1: å®‰è£…ä¾èµ–\n```bash\npip install langchain chromadb sentence-transformers openai pypdf\n```\n\n### Step 2: æ„å»ºçŸ¥è¯†åº“\n```python\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.embeddings import SentenceTransformerEmbeddings\nfrom langchain.vectorstores import Chroma\n\nloader = PyPDFLoader(\"your.pdf\")\ndocs = loader.load_and_split()\n\nembedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\ndb = Chroma.from_documents(docs, embedding)\n```\n\n### Step 3: åˆ›å»ºé—®ç­”é“¾\n```python\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\n\nqa = RetrievalQA.from_chain_type(\n    llm=OpenAI(api_key=\"ä½ çš„API_KEY\"),\n    chain_type=\"stuff\",\n    retriever=db.as_retriever()\n)\n\nprint(qa.run(\"è¿™ä»½ PDF ä¸»è¦è®²äº†ä»€ä¹ˆï¼Ÿ\"))\n```\n\nâœ… è¿™æ ·ä½ å°±èƒ½åˆ›å»ºä¸€ä¸ªâ€œèƒ½è¯» PDF å¹¶å›ç­”é—®é¢˜â€çš„å°å‹ RAG ç³»ç»Ÿäº†ï¼\n\n---\n\n## ğŸš€ äº”ã€è¿›é˜¶å­¦ä¹ è·¯çº¿\n\nå½“ä½ æŒæ¡äº†åŸºæœ¬çš„ Demo åï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡ä½ çš„æŠ€èƒ½ï¼š\n\n| é˜¶æ®µ | ç›®æ ‡ | æå‡æ–¹å‘ |\n|------|------|-----------|\n| æ£€ç´¢ä¼˜åŒ– | æé«˜å¬å›ç‡ | æ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡ï¼‰ |\n| Prompt ä¼˜åŒ– | æå‡å›ç­”è´¨é‡ | ä½¿ç”¨ PromptTemplate åŠ å¼ºä¸Šä¸‹æ–‡ç»“æ„ |\n| æ€§èƒ½æå‡ | æ”¯æŒé•¿æ–‡æ¡£ | MapReduce / Refine Chain |\n| ç§æœ‰éƒ¨ç½² | ç¦»çº¿è¿è¡Œ | Ollama + Chroma |\n\n---\n\n## ğŸ“š å…­ã€æ¨èå­¦ä¹ èµ„æº\n\n- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)\n- [LlamaIndex å…¥é—¨æ•™ç¨‹](https://docs.llamaindex.ai/)\n- B ç«™å…³é”®è¯ï¼šâ€œRAG å®æˆ˜â€æˆ–â€œLangChain ç§æœ‰é—®ç­”â€\n- è®ºæ–‡ï¼š*Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks* â€” Lewis et al., 2020\n\n---\n\n## â° ä¸ƒã€å­¦ä¹ èŠ‚å¥å»ºè®®\n\n| å‘¨ | ç›®æ ‡ |\n|----|------|\n| ç¬¬ 1 å‘¨ | æŒæ¡ embedding + å‘é‡ç›¸ä¼¼æ€§æ¦‚å¿µ |\n| ç¬¬ 2 å‘¨ | è·‘é€šç¬¬ä¸€ä¸ª PDF é—®ç­” demo |\n| ç¬¬ 3 å‘¨ | ç†è§£ä¸‰å¤§æ¨¡å—å¦‚ä½•é…åˆ |\n| ç¬¬ 4 å‘¨ | å°è¯•æœ¬åœ°åŒ–éƒ¨ç½²æˆ–å¤šæ–‡æ¡£ç®¡ç† |\n\n---\n\nğŸ¯ **æ€»ç»“ä¸€å¥è¯**  \nRAG çš„å­¦ä¹ å…³é”®åœ¨äºâ€œç†è§£ç»„æˆ + è·‘é€šæœ€å°ç³»ç»Ÿ + å¾ªåºä¼˜åŒ–â€ã€‚ä½ å®Œå…¨å¯ä»¥ç”¨ä¸€å°æ™®é€šç”µè„‘ï¼Œåœ¨ä¸¤å‘¨å†…æ„å»ºä¸€ä¸ªèƒ½å›ç­”ä½  PDF æˆ–ç¬”è®°é—®é¢˜çš„å° RAG æœºå™¨äººã€‚\n\nå¦‚æœä½ éœ€è¦ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¯è¿è¡Œçš„ RAG ç¤ºä¾‹è„šæœ¬ï¼Œå¸¦è¯¦ç»†æ³¨é‡Šå’Œ Prompt æ¨¡æ¿ã€‚åªéœ€å‘Šè¯‰æˆ‘ä½ æƒ³ç”¨å“ªç§æ•°æ®æºï¼ˆPDFã€Markdownã€ç½‘é¡µç­‰ï¼‰ï¼Œæˆ‘å°±èƒ½ä¸€æ­¥æ­¥å¸¦ä½ æ„å»ºå±äºä½ çš„ç¬¬ä¸€ä¸ª RAG Demoï¼ğŸš€ ä½ è§‰å¾—æ€ä¹ˆæ ·ï¼Ÿ",
      "timestamp": "2025-10-14 21:14:17"
    },
    {
      "type": "user",
      "content": "ragæ€ä¹ˆå­¦ä¹ ",
      "timestamp": "2025-10-14 21:15:06"
    },
    {
      "type": "assistant",
      "content": "å¤ªæ£’äº†ï¼ŒStudentï¼ğŸ¯ ä½ åˆåœ¨æ·±å…¥ç ”ç©¶ RAG äº†ï¼è®©æˆ‘ç»™ä½ ä¸€ä¸ªæ¸…æ™°ã€å¾ªåºæ¸è¿›çš„å­¦ä¹ è·¯å¾„ï¼Œå¸®åŠ©ä½ ç†è§£ RAG çš„å­¦ä¹ æœºåˆ¶ï¼Œå¹¶èƒ½è‡ªå·±å®ç°ä¸€ä¸ªå° Demoã€‚\n\n## ğŸ§­ ä¸€ã€äº†è§£ RAG çš„åŸºæœ¬æ¦‚å¿µ\n\n**RAGï¼ˆRetrieval-Augmented Generationï¼‰= æ£€ç´¢ + ç”Ÿæˆ**\n\nç®€å•æ¥è¯´ï¼ŒRAG çš„å·¥ä½œæ–¹å¼æ˜¯ï¼š\n1. å½“ä½ æé—®æ—¶ï¼Œç³»ç»Ÿé¦–å…ˆä¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„ä¿¡æ¯ã€‚\n2. ç„¶åæŠŠè¿™äº›æ£€ç´¢åˆ°çš„å†…å®¹å’Œä½ çš„é—®é¢˜ä¸€èµ·è¾“å…¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚\n3. æ¨¡å‹åŸºäºè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå›ç­”ï¼Œè¿™æ ·çš„å›ç­”é€šå¸¸æ›´åŠ å‡†ç¡®å’Œå¯é ã€‚\n\n> æƒ³è±¡ä¸€ä¸‹ RAG å°±æ˜¯ä¸€ä¸ªâ€œå¸¦æœç´¢åŠŸèƒ½çš„ ChatGPTâ€ï¼\n\n## ğŸ§± äºŒã€å…¥é—¨å‡†å¤‡ï¼ˆ1~2 å‘¨ï¼‰\n\nåœ¨ä½ å¼€å§‹ä¹‹å‰ï¼Œæœ‰å‡ ä¸ªå…³é”®çš„çŸ¥è¯†ç‚¹éœ€è¦æŒæ¡ï¼š\n\n| æ¨¡å— | é‡ç‚¹ç†è§£ | ç»ƒä¹ å»ºè®® |\n|------|------------|-----------|\n| **Python åŸºç¡€** | ç†è§£å¯¼åŒ…ã€å‡½æ•°å’Œç±» | å¯ä»¥å‚è€ƒã€ŠPython ç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µã€‹ |\n| **Embeddingï¼ˆæ–‡æœ¬å‘é‡ï¼‰** | äº†è§£å¦‚ä½•å°†æ–‡å­—è½¬æˆæ•°å­—åŒ–è¡¨ç¤º | è·‘ä¸‹é¢çš„ç›¸ä¼¼åº¦æµ‹è¯•ä»£ç  |\n| **å‘é‡æ•°æ®åº“** | å­¦ä¹ å¦‚ä½•å­˜å‚¨å’Œæ£€ç´¢ç›¸ä¼¼æ–‡æœ¬ | åˆæ­¥æ¥è§¦ FAISS æˆ– Chroma |\n\n### ç›¸ä¼¼åº¦æµ‹è¯•ç¤ºä¾‹ä»£ç ï¼š\n```python\nfrom sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nemb1 = model.encode(\"çŒ«å–œæ¬¢æ™’å¤ªé˜³\", convert_to_tensor=True)\nemb2 = model.encode(\"çŒ«åœ¨é˜³å…‰ä¸‹ä¼‘æ¯\", convert_to_tensor=True)\n\nprint(util.cos_sim(emb1, emb2))  # ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œæ–‡æœ¬è¶Šâ€œåƒâ€\n```\n\n## âš™ï¸ ä¸‰ã€RAG çš„ä¸‰å¤§æ ¸å¿ƒç»„ä»¶\n\nç†è§£è¿™ä¸‰å¤§ç»„ä»¶æ˜¯æ„å»º RAG ç³»ç»Ÿçš„åŸºç¡€ï¼š\n\n| æ¨¡å— | èŒè´£ | å·¥å…·ç¤ºä¾‹ |\n|------|------|----------|\n| **Retrieverï¼ˆæ£€ç´¢å™¨ï¼‰** | ä»çŸ¥è¯†åº“ä¸­æ‰¾å‡ºæœ€ç›¸å…³çš„å†…å®¹ | Chroma / FAISS |\n| **Augmenterï¼ˆå¢å¼ºå™¨ï¼‰** | ç»„åˆé—®é¢˜å’Œæ£€ç´¢ç»“æœï¼Œå½¢æˆ prompt | LangChain / LlamaIndex |\n| **Generatorï¼ˆç”Ÿæˆå™¨ï¼‰** | è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆå›ç­” | OpenAI / Claude / Ollama / Llama3 |\n\næŒæ¡è¿™ä¸‰éƒ¨åˆ†ï¼Œä½ å°±èƒ½æ­å»ºä¸€ä¸ªå®Œæ•´çš„ RAG æµç¨‹ã€‚\n\n## ğŸ’» å››ã€ä½ çš„ç¬¬ä¸€ä¸ª RAG Demoï¼šPDF é—®ç­”æœºå™¨äºº\n\n### Step 1: å®‰è£…ä¾èµ–\n```bash\npip install langchain chromadb sentence-transformers openai pypdf\n```\n\n### Step 2: æ„å»ºçŸ¥è¯†åº“\n```python\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.embeddings import SentenceTransformerEmbeddings\nfrom langchain.vectorstores import Chroma\n\nloader = PyPDFLoader(\"your.pdf\")\ndocs = loader.load_and_split()\n\nembedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\ndb = Chroma.from_documents(docs, embedding)\n```\n\n### Step 3: åˆ›å»ºé—®ç­”é“¾\n```python\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\n\nqa = RetrievalQA.from_chain_type(\n    llm=OpenAI(api_key=\"ä½ çš„API_KEY\"),\n    chain_type=\"stuff\",\n    retriever=db.as_retriever()\n)\n\nprint(qa.run(\"è¿™ä»½ PDF ä¸»è¦è®²äº†ä»€ä¹ˆï¼Ÿ\"))\n```\n\nâœ… è¿™æ ·ä½ å°±èƒ½åˆ›å»ºä¸€ä¸ªâ€œèƒ½è¯» PDF å¹¶å›ç­”é—®é¢˜â€çš„å°å‹ RAG ç³»ç»Ÿäº†ï¼\n\n## ğŸš€ äº”ã€è¿›é˜¶å­¦ä¹ è·¯çº¿\n\nå½“ä½ æŒæ¡äº†åŸºæœ¬çš„ Demo åï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡ä½ çš„æŠ€èƒ½ï¼š\n\n| é˜¶æ®µ | ç›®æ ‡ | æå‡æ–¹å‘ |\n|------|------|-----------|\n| æ£€ç´¢ä¼˜åŒ– | æé«˜å¬å›ç‡ | æ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡ï¼‰ |\n| Prompt ä¼˜åŒ– | æå‡å›ç­”è´¨é‡ | ä½¿ç”¨ PromptTemplate åŠ å¼ºä¸Šä¸‹æ–‡ç»“æ„ |\n| æ€§èƒ½æå‡ | æ”¯æŒé•¿æ–‡æ¡£ | MapReduce / Refine Chain |\n| ç§æœ‰éƒ¨ç½² | ç¦»çº¿è¿è¡Œ | Ollama + Chroma |\n\n## ğŸ“š å…­ã€æ¨èå­¦ä¹ èµ„æº\n\n- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)\n- [LlamaIndex å…¥é—¨æ•™ç¨‹](https://docs.llamaindex.ai/)\n- B ç«™å…³é”®è¯ï¼šâ€œRAG å®æˆ˜â€æˆ–â€œLangChain ç§æœ‰é—®ç­”â€\n- è®ºæ–‡ï¼š*Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks* â€” Lewis et al., 2020\n\n## â° ä¸ƒã€å­¦ä¹ èŠ‚å¥å»ºè®®\n\n| å‘¨ | ç›®æ ‡ |\n|----|------|\n| ç¬¬ 1 å‘¨ | æŒæ¡ embedding + å‘é‡ç›¸ä¼¼æ€§æ¦‚å¿µ |\n| ç¬¬ 2 å‘¨ | è·‘é€šç¬¬ä¸€ä¸ª PDF é—®ç­” demo |\n| ç¬¬ 3 å‘¨ | ç†è§£ä¸‰å¤§æ¨¡å—å¦‚ä½•é…åˆ |\n| ç¬¬ 4 å‘¨ | å°è¯•æœ¬åœ°åŒ–éƒ¨ç½²æˆ–å¤šæ–‡æ¡£ç®¡ç† |\n\nğŸ¯ **æ€»ç»“ä¸€å¥è¯**  \nRAG çš„å­¦ä¹ å…³é”®åœ¨äºâ€œç†è§£ç»„æˆ + è·‘é€šæœ€å°ç³»ç»Ÿ + å¾ªåºä¼˜åŒ–â€ã€‚ä½ å®Œå…¨å¯ä»¥ç”¨ä¸€å°æ™®é€šç”µè„‘ï¼Œåœ¨ä¸¤å‘¨å†…æ„å»ºä¸€ä¸ªèƒ½å›ç­”ä½  PDF æˆ–ç¬”è®°é—®é¢˜çš„å° RAG æœºå™¨äººã€‚\n\nå¦‚æœä½ éœ€è¦ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¯è¿è¡Œçš„ RAG ç¤ºä¾‹è„šæœ¬ï¼Œå¸¦è¯¦ç»†æ³¨é‡Šå’Œ Prompt æ¨¡æ¿ã€‚åªéœ€å‘Šè¯‰æˆ‘ä½ æƒ³ç”¨å“ªç§æ•°æ®æºï¼ˆPDFã€Markdownã€ç½‘é¡µç­‰ï¼‰ï¼Œæˆ‘å°±èƒ½ä¸€æ­¥æ­¥å¸¦ä½ æ„å»ºå±äºä½ çš„ç¬¬ä¸€ä¸ª RAG Demoï¼ğŸš€ ä½ è§‰å¾—æ€ä¹ˆæ ·ï¼Ÿ",
      "timestamp": "2025-10-14 21:15:06"
    }
  ],
  "title": "ragæ€ä¹ˆå­¦ä¹ "
}